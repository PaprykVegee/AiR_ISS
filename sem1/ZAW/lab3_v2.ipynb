{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorium 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "input_folder = \"/home/plorenc/Desktop/AiR_ISS/AVS/pedestrian/input/\"\n",
    "ref_folder = \"/home/plorenc/Desktop/AiR_ISS/AVS/pedestrian/groundtruth\"\n",
    "\n",
    "def calculate_f1_score(thresh, I_ref):\n",
    "    # Binaryzacja maski referencyjnej\n",
    "    I_ref = cv2.threshold(I_ref, 127, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    # Obliczenie True Positives, False Positives, False Negatives\n",
    "    TP = np.sum((thresh == 255) & (I_ref == 255))\n",
    "    FP = np.sum((thresh == 255) & (I_ref == 0))\n",
    "    FN = np.sum((thresh == 0) & (I_ref == 255))\n",
    "\n",
    "    # Oblicz Precision i Recall\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "    # Oblicz F1-score\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return (f1, precision, recall)\n",
    "\n",
    "def f1_for_video(f1):\n",
    "    sumf = 0\n",
    "    num = 0\n",
    "    for f in f1:\n",
    "        if f[0] != 0:\n",
    "            sumf += f[0]\n",
    "            num += 1\n",
    "    return round(sumf/num, 2)\n",
    "\n",
    "def thres_and_morph(I, thres=10, ksize=3, iterations=1):\n",
    "    _, I = cv2.threshold(I, thres, 255, cv2.THRESH_BINARY)\n",
    "    I = cv2.medianBlur(I, ksize=ksize)\n",
    "    \n",
    "    #kernel = np.ones((ksize, ksize), np.uint8) \n",
    "    I = cv2.morphologyEx(I, cv2.MORPH_OPEN, (3, 3), iterations=iterations)\n",
    "\n",
    "    return I\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zadanie 1 BUFFOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "N = 60  # Rozmiar bufora\n",
    "threshold_value = 20  # Wartość progowania dla detekcji ruchu\n",
    "\n",
    "input_folder = \"/home/plorenc/Desktop/AiR_ISS/AVS/pedestrian/input/\"\n",
    "\n",
    "ref_folder = \"/home/plorenc/Desktop/AiR_ISS/AVS/pedestrian/groundtruth\"\n",
    "f1_med = []\n",
    "f1_mean = []\n",
    "\n",
    "first_image = cv2.imread(os.path.join(input_folder, \"in000300.jpg\"), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "YY, XX = first_image.shape \n",
    "\n",
    "BUF = np.zeros((YY, XX, N), np.uint8) # buffor \n",
    "iN = 0  # Licznik bufora\n",
    "\n",
    "for i in range(900, 1100):  \n",
    "    image_path = os.path.join(input_folder, f\"in{i:06d}.jpg\")\n",
    "    ref_path = os.path.join(ref_folder, f\"gt{i:06d}.png\")\n",
    "\n",
    "    IG = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    ref_img = cv2.imread(ref_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if iN < N:\n",
    "        BUF[:, :, iN] = IG # buffor jest napełniany\n",
    "        iN += 1\n",
    "    else:\n",
    "        BUF = np.roll(BUF, -1, axis=2)  # po przepełnieniu pierwszy eleent jest usuwany a jako ostani jest dołączony nowy obraz\n",
    "        BUF[:, :, -1] = IG  \n",
    "\n",
    "    if iN > 59:\n",
    "        background_mean = np.mean(BUF, axis=2).astype(np.uint8) # z tensora po osotaniej osi jest obliczna srednia\n",
    "        background_median = np.median(BUF, axis=2).astype(np.uint8) # z tensora po ostaniej osi jest liczona mediana\n",
    "\n",
    "        fg_mask_mean = cv2.absdiff(IG, background_mean) # maska tła dla sredniej \n",
    "        fg_mask_median = cv2.absdiff(IG, background_median) # maska tła dla mediany \n",
    "\n",
    "        _, fg_mask_mean = cv2.threshold(fg_mask_mean, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "        _, fg_mask_median = cv2.threshold(fg_mask_median, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "        fg_mask_mean = cv2.medianBlur(fg_mask_mean, 5)\n",
    "        fg_mask_median = cv2.medianBlur(fg_mask_median, 5)\n",
    "        \n",
    "        fg_mask_mean = cv2.morphologyEx(fg_mask_mean, cv2.MORPH_OPEN, (7, 7), iterations=3)\n",
    "        fg_mask_median = cv2.morphologyEx(fg_mask_median, cv2.MORPH_OPEN, (7, 7), iterations=3)\n",
    "\n",
    "        f1_med.append(calculate_f1_score(fg_mask_median, ref_img))\n",
    "        f1_mean.append(calculate_f1_score(fg_mask_mean, ref_img))\n",
    "\n",
    "        combined_image = cv2.hconcat([fg_mask_mean, fg_mask_median])\n",
    "        cv2.imshow(\"Foreground Mask\", combined_image)\n",
    "\n",
    "        cv2.waitKey(10)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.53, 0.77)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_for_video(f1_mean), f1_for_video(f1_med)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zadanie 2 Aproksymacja mediany i średniej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.2\n",
    "\n",
    "first_image = cv2.imread(os.path.join(input_folder, \"in000300.jpg\"), cv2.IMREAD_GRAYSCALE)\n",
    "YY, XX = first_image.shape\n",
    "\n",
    "bg_mean = first_image.astype(np.float32)\n",
    "bg_median = first_image.astype(np.uint8)\n",
    "\n",
    "f1_med = []\n",
    "f1_mean = []\n",
    "\n",
    "for i in range(300, 1100, 1):\n",
    "    I_path = os.path.join(input_folder, f\"in{i:06d}.jpg\")\n",
    "    I_ref_path = os.path.join(ref_folder, f\"gt{i:06d}.png\")\n",
    "\n",
    "    I = cv2.imread(I_path, cv2.IMREAD_GRAYSCALE)\n",
    "    I_ref = cv2.imread(I_ref_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    bg_mean = alpha*I + (1-alpha)*bg_mean\n",
    "    bg_mean = bg_mean.astype(np.uint8)\n",
    "\n",
    "    bg_median[bg_median < I] += 1\n",
    "    bg_median[bg_median > I] -= 1\n",
    "\n",
    "    diff_mean = cv2.absdiff(I, bg_mean)\n",
    "    diff_median = cv2.absdiff(I, bg_median)\n",
    "\n",
    "    diff_mean = thres_and_morph(diff_mean, ksize=3, iterations=2)\n",
    "    diff_median = thres_and_morph(diff_median, ksize=3, iterations=2)\n",
    "\n",
    "    combine = cv2.hconcat([diff_mean, diff_median])\n",
    "\n",
    "    f1_med.append(calculate_f1_score(diff_median, I_ref))\n",
    "    f1_mean.append(calculate_f1_score(diff_mean, I_ref))\n",
    "\n",
    "    cv2.imshow(\"test\", combine)\n",
    "    cv2.waitKey(10)\n",
    "\n",
    "    \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.62, 0.81)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_for_video(f1_mean), f1_for_video(f1_med)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 3 Polityka konserwatywna i liberalna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.2\n",
    "\n",
    "first_image = cv2.imread(os.path.join(input_folder, \"in000300.jpg\"), cv2.IMREAD_GRAYSCALE)\n",
    "YY, XX = first_image.shape\n",
    "\n",
    "bg_mean = first_image.astype(np.float32)\n",
    "bg_median = first_image.astype(np.uint8)\n",
    "\n",
    "f1_med = []\n",
    "f1_mean = []\n",
    "\n",
    "for i in range(300, 900, 1):\n",
    "    I_path = os.path.join(input_folder, f\"in{i:06d}.jpg\")\n",
    "    I_ref_path = os.path.join(ref_folder, f\"gt{i:06d}.png\")\n",
    "\n",
    "    I = cv2.imread(I_path, cv2.IMREAD_GRAYSCALE)\n",
    "    I_ref = cv2.imread(I_ref_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    _, mask_mean = cv2.threshold(bg_mean, 30, 255, cv2.THRESH_BINARY)\n",
    "    _, mask_median = cv2.threshold(bg_median, 30, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    mask_mean = mask_mean == 0 # zostało sklaifikowanie jako tło \n",
    "    mask_median = mask_median == 0 # zostało sklaifikowanie jako tło \n",
    "\n",
    "    bg_mean[mask_mean] = alpha * I[mask_mean] + (1 - alpha) * bg_mean[mask_mean]\n",
    "    \n",
    "    bg_median[(bg_median < I) & (mask_median == 0)] += 1\n",
    "    bg_median[(bg_median > I) & (mask_median == 0)] -= 1\n",
    "\n",
    "    diff_mean = cv2.absdiff(I, bg_mean.astype(np.uint8))\n",
    "    diff_median = cv2.absdiff(I, bg_median)\n",
    "\n",
    "    diff_mean = thres_and_morph(diff_mean, ksize=5, iterations=2)\n",
    "    diff_median = thres_and_morph(diff_median, ksize=5, iterations=2)\n",
    "\n",
    "    combine = cv2.hconcat([diff_mean, diff_median])\n",
    "\n",
    "    f1_med.append(calculate_f1_score(diff_median, I_ref))\n",
    "    f1_mean.append(calculate_f1_score(diff_mean, I_ref))\n",
    "\n",
    "    cv2.imshow(\"test\", combine)\n",
    "    cv2.waitKey(10)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.74, 0.82)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_for_video(f1_mean), f1_for_video(f1_med)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 4 MOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image = cv2.imread(os.path.join(input_folder, \"in000300.jpg\"), cv2.IMREAD_GRAYSCALE)\n",
    "YY, XX = first_image.shape\n",
    "\n",
    "bg_mean = first_image.astype(np.float32)\n",
    "bg_median = first_image.astype(np.uint8)\n",
    "\n",
    "f1_mog = []\n",
    "\n",
    "history = 500\n",
    "varThras = 10\n",
    "\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2(history=history, varThreshold=varThras, detectShadows=False)\n",
    "\n",
    "for i in range(300, 1100, 2):\n",
    "    I_path = os.path.join(input_folder, f\"in{i:06d}.jpg\")\n",
    "    I_ref_path = os.path.join(ref_folder, f\"gt{i:06d}.png\")\n",
    "\n",
    "    I = cv2.imread(I_path, cv2.IMREAD_GRAYSCALE)\n",
    "    I_ref = cv2.imread(I_ref_path, cv2.IMREAD_GRAYSCALE)\n",
    "    bg = bg_subtractor.apply(I, learningRate=-1)\n",
    "\n",
    "    bg = thres_and_morph(bg, ksize=5, iterations=2)\n",
    "\n",
    "    f1_mog.append(calculate_f1_score(bg, I_ref))\n",
    "\n",
    "    cv2.imshow(\"test\", bg)\n",
    "    cv2.waitKey(10)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_for_video(f1_mog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 5 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image = cv2.imread(os.path.join(input_folder, \"in000300.jpg\"), cv2.IMREAD_GRAYSCALE)\n",
    "YY, XX = first_image.shape\n",
    "\n",
    "bg_mean = first_image.astype(np.float32)\n",
    "bg_median = first_image.astype(np.uint8)\n",
    "\n",
    "f1_knn = []\n",
    "\n",
    "history = 500\n",
    "dist2Threshold = 70\n",
    "\n",
    "bg_subtractor = cv2.createBackgroundSubtractorKNN(history=history, dist2Threshold=dist2Threshold, detectShadows=False)\n",
    "\n",
    "for i in range(300, 1100, 2):\n",
    "    I_path = os.path.join(input_folder, f\"in{i:06d}.jpg\")\n",
    "    I_ref_path = os.path.join(ref_folder, f\"gt{i:06d}.png\")\n",
    "\n",
    "    I = cv2.imread(I_path, cv2.IMREAD_GRAYSCALE)\n",
    "    I_ref = cv2.imread(I_ref_path, cv2.IMREAD_GRAYSCALE)\n",
    "    bg = bg_subtractor.apply(I, learningRate=-1)\n",
    "\n",
    "    bg = thres_and_morph(bg, ksize=5, iterations=2)\n",
    "\n",
    "    f1_knn.append(calculate_f1_score(bg, I_ref))\n",
    "\n",
    "    cv2.imshow(\"test\", bg)\n",
    "    cv2.waitKey(10)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_for_video(f1_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sieć neuronowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 6 Dodatkowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_prew = cv2.imread(os.path.join(input_folder, \"in000300.jpg\"), cv2.IMREAD_GRAYSCALE)\n",
    "YY, XX = I_prew.shape\n",
    "\n",
    "# Parametry\n",
    "threshold_tolerance = 0.8\n",
    "N = 30  # Rozmiar bufora\n",
    "iN = 0\n",
    "\n",
    "# Inicjalizacja bufora tła\n",
    "BUFFOR = np.zeros([YY, XX, N], dtype=np.uint8)\n",
    "\n",
    "for i in range(301, 1100):\n",
    "    I_path = os.path.join(input_folder, f\"in{i:06d}.jpg\")\n",
    "    I = cv2.imread(I_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Obliczenie różnicy pomiędzy klatkami\n",
    "    I_dif = cv2.absdiff(I, I_prew)\n",
    "    I_prew = I\n",
    "\n",
    "    # Progowanie maski różnic\n",
    "    _, bg = cv2.threshold(I_dif, np.mean(I_dif) * threshold_tolerance, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Konwersja do wartości 0 lub 1 (uint8)\n",
    "    bg = (bg > 0).astype(np.uint8)\n",
    "\n",
    "    # Aktualizacja bufora\n",
    "    if iN < N:\n",
    "        BUFFOR[:, :, iN] = bg\n",
    "        iN += 1\n",
    "    else:\n",
    "        BUFFOR = np.roll(BUFFOR, -1, axis=2)\n",
    "        BUFFOR[:, :, -1] = bg\n",
    "\n",
    "    # Generowanie maski tła po zapełnieniu bufora\n",
    "    if iN == N:\n",
    "        mask = np.sum(BUFFOR, axis=2)\n",
    "\n",
    "        # Tworzenie maski obszarów tła\n",
    "        bg_final = np.zeros([YY, XX], dtype=np.uint8)\n",
    "        bg_final[mask > (threshold_tolerance * N)] = 255  # Próg dla stabilnych pikseli\n",
    "\n",
    "        # Operacje morfologiczne (opcjonalne)\n",
    "        bg_final = cv2.dilate(bg_final, None, iterations=2)\n",
    "        bg_final = cv2.erode(bg_final, None, iterations=2)\n",
    "\n",
    "        cv2.imshow(\"Background\", bg_final)\n",
    "\n",
    "    cv2.waitKey(10)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 7 Dodatkowe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorytm VIBE (Visual Background Extractor) wykrywa ruch poprzez przechowywanie zbioru próbek pikseli dla każdego punktu obrazu i porównywanie nowych wartości do tych próbek. Jeśli nowa wartość pasuje do co najmniej określonej liczby próbek, uznawana jest za tło, a w przeciwnym razie traktowana jako obiekt w ruchu. Co pewien czas algorytm losowo aktualizuje próbki, aby dostosować się do zmian w scenie. Dzięki temu VIBE jest szybki, adaptacyjny i efektywny w wykrywaniu obiektów w ruchu w statycznym tle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViBE:\n",
    "    def __init__(self, num_samples=100, min_matches=3, radius=30):\n",
    "        self.num_samples = num_samples  # Liczba próbek tła dla każdego piksela\n",
    "        self.min_matches = min_matches  # Minimalna liczba dopasowań do uznania piksela za tło\n",
    "        self.radius = radius            # Promień porównywania jasności\n",
    "        self.background_model = None    # Model tła\n",
    "\n",
    "    def initialize(self, frame):\n",
    "        \"\"\"Inicjalizacja modelu tła na podstawie pierwszej klatki.\"\"\"\n",
    "        h, w = frame.shape\n",
    "        self.background_model = np.zeros((h, w, self.num_samples), dtype=np.uint8) # Inicjacja modelu tła zerami \n",
    "        for i in range(self.num_samples):\n",
    "            noise_x = np.random.randint(-5, 5, size=(h, w))  # dodanie szumu do modelu tła że był bardziej odporny na rzeczywiste zakłócenia  \n",
    "            noise_y = np.random.randint(-5, 5, size=(h, w))\n",
    "            x_idx = np.clip(np.arange(w) + noise_x, 0, w - 1)\n",
    "\n",
    "            \n",
    "            y_idx = np.clip(np.arange(h)[:, np.newaxis] + noise_y, 0, h - 1)\n",
    "            \n",
    "            self.background_model[:, :, i] = frame[y_idx, x_idx]\n",
    "\n",
    "\n",
    "    def apply(self, frame):\n",
    "        \"\"\"Zwraca maskę pierwszego planu na podstawie aktualnej klatki.\"\"\"\n",
    "        if self.background_model is None:\n",
    "            self.initialize(frame)\n",
    "        \n",
    "        h, w = frame.shape\n",
    "        fg_mask = np.zeros((h, w), dtype=np.uint8)\n",
    "\n",
    "        for i in range(self.num_samples):\n",
    "            matches = cv2.absdiff(frame, self.background_model[:, :, i]) < self.radius # Odejmujemy warosci i patrzymy czy roznice sa znczące \n",
    "            fg_mask += matches.astype(np.uint8)\n",
    "\n",
    "        fg_mask = (fg_mask < self.min_matches).astype(np.uint8) * 255\n",
    "        return fg_mask\n",
    "\n",
    "\n",
    "first_image_path = os.path.join(input_folder, \"in000300.jpg\")\n",
    "first_image = cv2.imread(first_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# inicjalizacja algorytmu ViBE\n",
    "vibe = ViBE()\n",
    "vibe.initialize(first_image)\n",
    "\n",
    "f1_vibe = []\n",
    "\n",
    "for i in range(300, 500, 1):\n",
    "    I_path = os.path.join(input_folder, f\"in{i:06d}.jpg\")\n",
    "    I_ref_path = os.path.join(ref_folder, f\"gt{i:06d}.png\")\n",
    "\n",
    "    I = cv2.imread(I_path, cv2.IMREAD_GRAYSCALE)\n",
    "    I_ref = cv2.imread(I_ref_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    fg_mask = vibe.apply(I)\n",
    "\n",
    "    fg_mask = thres_and_morph(fg_mask, ksize=3)\n",
    "\n",
    "    cv2.imshow(\"Foreground Mask\", fg_mask)\n",
    "\n",
    "    f1_vibe.append(calculate_f1_score(fg_mask, I_ref))\n",
    "\n",
    "    cv2.waitKey(10)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_for_video(f1_vibe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorytm PBAS (Pixel-Based Adaptive Segmenter) działa na zasadzie dynamicznej adaptacji progu detekcji ruchu dla każdego piksela. Tworzy histogram wartości pikseli w czasie i na jego podstawie ocenia, czy dany piksel należy do tła. W przeciwieństwie do VIBE, PBAS dostosowuje próg czułości indywidualnie dla każdego piksela, co pozwala lepiej radzić sobie z dynamicznie zmieniającym się tłem, np. falującą wodą czy migoczącymi światłami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PBAS:\n",
    "    def __init__(self, history=100, threshold=2, alpha=0.05):\n",
    "        self.history = history          # Liczba zapamiętanych klatek\n",
    "        self.threshold = threshold      # Początkowa wartość progowa\n",
    "        self.alpha = alpha              # Tempo adaptacji progu\n",
    "        self.samples = None             # Historia wartości pikseli\n",
    "        self.dynamic_threshold = None   # Dynamiczne progi dla każdego piksela\n",
    "\n",
    "    def initialize(self, frame):\n",
    "        \"\"\" Inicjalizacja pamięci dla historii pikseli \"\"\"\n",
    "        h, w = frame.shape\n",
    "        self.samples = np.zeros((h, w, self.history), dtype=np.uint8)  \n",
    "        self.dynamic_threshold = np.full((h, w), self.threshold, dtype=np.float32) # Tablica h na w wypełniona wartosciami self.threshold\n",
    "\n",
    "        for i in range(self.history):\n",
    "            self.samples[:, :, i] = frame\n",
    "\n",
    "    def apply(self, frame):\n",
    "        \"\"\" Aktualizuje model i zwraca maskę ruchu \"\"\"\n",
    "        if self.samples is None:\n",
    "            self.initialize(frame)\n",
    "\n",
    "        h, w = frame.shape\n",
    "        fg_mask = np.ones((h, w), dtype=np.uint8) * 255\n",
    "\n",
    "        # Obliczamy odległość do każdego z zapamiętanych pikseli\n",
    "        dist = np.abs(self.samples - frame[:, :, None])\n",
    "        #dist = cv2.absdiff(self.samples, frame[:, :, None])\n",
    "        match = np.any(dist < self.dynamic_threshold[:, :, None], axis=2)\n",
    "\n",
    "        # Ustawienie maski ruchu\n",
    "        fg_mask[match] = 0\n",
    "\n",
    "        self.dynamic_threshold += self.alpha * ((fg_mask == 255) - 0.5)\n",
    "\n",
    "        # Aktualizacja historii pikseli\n",
    "        rand_idx = np.random.randint(0, self.history, (h, w))\n",
    "        update_mask = (np.random.rand(h, w) < 0.05)  # 5% losowych aktualizacji\n",
    "        self.samples[np.arange(h)[:, None], np.arange(w), rand_idx] = frame\n",
    "\n",
    "        return fg_mask\n",
    "    \n",
    "    \n",
    "# Wczytanie pierwszego obrazu do inicjalizacji modelu\n",
    "first_image_path = os.path.join(input_folder, \"in000300.jpg\")\n",
    "first_image = cv2.imread(first_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Inicjalizacja algorytmu ViBE\n",
    "pbsa = PBAS()\n",
    "pbsa.initialize(first_image)\n",
    "\n",
    "f1_pbsa = []\n",
    "\n",
    "for i in range(300, 1100, 1):\n",
    "    I_path = os.path.join(input_folder, f\"in{i:06d}.jpg\")\n",
    "    I_ref_path = os.path.join(ref_folder, f\"gt{i:06d}.png\")\n",
    "\n",
    "    I = cv2.imread(I_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    fg_mask = pbsa.apply(I)\n",
    "\n",
    "    cv2.imshow(\"Foreground Mask\", fg_mask)\n",
    "\n",
    "    fg_mask = thres_and_morph(fg_mask)\n",
    "\n",
    "    fg_mask = f1_pbsa.append(fg_mask)\n",
    "\n",
    "    cv2.waitKey(10)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
