{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01e4263f",
   "metadata": {},
   "source": [
    "# Lab 1 - Introduction to Deep Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4024334e",
   "metadata": {},
   "source": [
    "Nowadays, it is difficult to find someone who has not encountered neural networks in one form or another. Among the most obvious examples, almost everyone has heard of ChatGPT, which is based on large language models (LLMs – Large Language Models), or has used Google Search, which also relies on language models to better understand user queries. However, neural networks are applied in many other fields, such as image recognition, audio analysis, computer games, and even medicine, where they assist in diagnosing diseases. Due to their versatility and rapid development, it is worth learning the basics of how neural networks work and how they can be applied in various domains.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/vision-agh/DNN-Course-media/refs/heads/main/lab1_introduction/figures/google.png\" alt=\"Google AI Response\" width=\"600\"/>\n",
    "\n",
    "\n",
    "The aim of these course is to introduce the fundamental concepts related to neural networks, to learn how to use popular libraries for building and training them, such as PyTorch, and to understand the process of machine learning.\n",
    "\n",
    "During the course, we will explore some of the most popular neural network architectures, such as:\n",
    "- MLP (Multi-Layer Perceptron)\n",
    "- CNN (Convolutional Neural Networks)\n",
    "- RNN (Recurrent Neural Networks)\n",
    "- GNN (Graph Neural Networks)\n",
    "- SNN (Spiking Neural Networks)\n",
    "- Transformers for natural language processing (NLP) as well as computer vision (CV)\n",
    "- Generative models (GANs, Diffusion Models)\n",
    "- and others.\n",
    "\n",
    "We will also cover different machine learning techniques, such as supervised, unsupervised, and reinforcement learning, along with methods like knowledge distillation and transfer learning.\n",
    "\n",
    "As you can see, the scope of material is very broad, and it is impossible to cover everything within a single semester. However, I hope that by the end of the course you will have a solid foundation for further learning and experimenting with neural networks. 🙂"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6f5b4a",
   "metadata": {},
   "source": [
    "# What is a deep neural network?\n",
    "\n",
    "As we can see in the illustration above, which shows feedback generated by Google Gemini, neural networks are systems inspired by the structure and functioning of the human brain. The division into Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL), and Generative AI (GAI) is often confusing, but it can be clarified using the diagram below (source: [link](https://commons.wikimedia.org/wiki/File:Unraveling_AI_Complexity_-_A_Comparative_View_of_AI,_Machine_Learning,_Deep_Learning,_and_Generative_AI.png)):\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/vision-agh/DNN-Course-media/refs/heads/main/lab1_introduction/figures/comparison.png\" alt=\"AI, ML, DL, GAI\" width=\"600\"/>\n",
    "\n",
    "Deep neural networks consist of many interconnected layers. Neurons are organized into layers: the input layer receives the data, hidden layers process it, and the output layer generates the final prediction. Three main elements are essential for training a neural network:\n",
    "\n",
    "1. **Data** – Neural networks learn from datasets, which provide information about patterns and dependencies. \n",
    "2. **Architecture** – The structure of the network, i.e. the number of layers, the number of neurons in each layer, type of layers and how they are connected. Different architectures are better suited for different types of tasks.\n",
    "3. **Learning algorithm** – The method by which the network adjusts its weights and biases based on training data to minimize prediction error. The most commonly used approach is backpropagation, combined with optimizers such as Adam or Stochastic Gradient Descent (SGD).\n",
    "\n",
    "Based on the type of training data, machine learning can be divided into three main categories:\n",
    "- **Supervised Learning** – The network learns from labeled data, where each input is paired with a known output (label or value). The goal is to predict correct outputs for unseen data.\n",
    "- **Unsupervised Learning** – The network learns from unlabeled data, without known outputs. The goal is to discover hidden patterns or structures, such as clustering or dimensionality reduction.\n",
    "- **Reinforcement Learning** – The network learns through interaction with an environment (simulation), receiving rewards or penalties based on its actions. The goal is to learn optimal decision-making strategies within that environment.\n",
    "\n",
    "For now, without going into too much detail, I encourage you to explore the following resources:\n",
    "\n",
    "- https://www.geeksforgeeks.org/machine-learning/supervised-vs-reinforcement-vs-unsupervised/\n",
    "- https://medium.com/@bensalemh300/supervised-vs-unsupervised-vs-reinforcement-learning-a3e7bcf1dd23\n",
    "- https://www.youtube.com/watch?v=aircAruvnKk\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bce876e",
   "metadata": {},
   "source": [
    "### Envirenment setup\n",
    "\n",
    "During the course, we will primarily use Python and the following libraries:\n",
    "\n",
    "* **PyTorch** ([https://pytorch.org/](https://pytorch.org/)) – a widely used library for building and training neural networks, popular in both academia and industry.\n",
    "* **PyTorch Geometric** ([https://pytorch-geometric.readthedocs.io/en/latest/](https://pytorch-geometric.readthedocs.io/en/latest/)) – an extension of PyTorch designed for working with graphs and graph neural networks.\n",
    "* **snnTorch** ([https://snntorch.readthedocs.io/en/latest/](https://snntorch.readthedocs.io/en/latest/)) – a library for building and training spiking neural networks (SNNs).\n",
    "* **PyTorch Lightning** ([https://www.pytorchlightning.ai/](https://www.pytorchlightning.ai/)) – a high-level interface for PyTorch that simplifies model training and experiment management. We will start using it later in the course.\n",
    "* **Weights & Biases (W&B)** ([https://wandb.ai/](https://wandb.ai/)) – a tool for experiment tracking, result visualization, and machine learning project management. We will use it for logging our experiments, and it integrates seamlessly with PyTorch Lightning.\n",
    "\n",
    "Additionally, we will rely on standard data analysis and visualization libraries, such as **NumPy**, **Pandas**, **Matplotlib**, **OpenCV**, and others.\n",
    "The exercises have been prepared and tested with GPU acceleration using **Jupyter Notebook** and a **Conda virtual environment**. Below is the environment setup guide (for Linux and CUDA 12.8):\n",
    "\n",
    "```bash\n",
    "conda create -n dnn python=3.9\n",
    "conda activate dnn\n",
    "\n",
    "pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu128\n",
    "pip3 install torch_geometric\n",
    "pip3 install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.8.0+cu128.html\n",
    "pip3 install omegaconf opencv-python matplotlib psutil wandb lightning numba pybind11 tqdm pandas tonic\n",
    "pip3 install lightning snntorch\n",
    "```\n",
    "\n",
    "It is possible that during some classes we will need to install additional libraries; I will inform you about this as needed.\n",
    "If you do not have access to a GPU or prefer not to run computations on your own machine, you can use **Google Colab** ([https://colab.research.google.com/](https://colab.research.google.com/)), which provides free (but limited) GPU access in the cloud. In that case, you can copy the Jupyter Notebook code into Colab and run it there. However, keep in mind that library version conflicts may occur, so it is recommended to install the required versions manually in a Colab cell when necessary.\n",
    "\n",
    "\n",
    "## W&B Setup\n",
    "\n",
    "To use Weights & Biases (W&B) for experiment tracking, you need to create an account on their platform. You can sign up for free at [https://wandb.ai/](https://wandb.ai/). After creating an account, you will receive an API key that you will use to log in from your code (User Settings -> Scroll Down and Reveal API keys). \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/vision-agh/DNN-Course-media/refs/heads/main/lab1_introduction/figures/api.png\" alt=\"W&B API Key\" width=\"600\"/>\n",
    "\n",
    "\n",
    "During the first run of a script that uses W&B, you will be prompted to enter your API key to authenticate your account. You can also log in directly from a Jupyter Notebook cell using the following command:\n",
    "\n",
    "```python\n",
    "!wandb login YOUR_API_KEY\n",
    "```\n",
    "\n",
    "from the terminal:\n",
    "\n",
    "```bash\n",
    "wandb login YOUR_API_KEY\n",
    "```\n",
    "\n",
    "or in Colab:\n",
    "\n",
    "```python\n",
    "!pip install wandb\n",
    "!wandb login YOUR_API_KEY\n",
    "```\n",
    "\n",
    "or set the environment variable `WANDB_API_KEY` with your API key:\n",
    "\n",
    "```python\n",
    "import os\n",
    "import wandb\n",
    "\n",
    "wandb.login()\n",
    "os.environ['WANDB_API_KEY'] = 'YOUR_API_KEY'\n",
    "```\n",
    "\n",
    "All projects and experiments will be organized in W&B dashboard, where you can visualize metrics, compare runs, and manage your machine learning projects. After inviting you to the course project, you will be able to see all the experiments we conduct during the classes under this link: [https://wandb.ai/imperator/deep-neural-network-course](https://wandb.ai/imperator/deep-neural-network-course).\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/vision-agh/DNN-Course-media/refs/heads/main/lab1_introduction/figures/wandb.png\" alt=\"W&B Dashboard\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8380dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Downloading wandb-0.22.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.6/19.6 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pydantic<3\n",
      "  Downloading pydantic-2.11.10-py3-none-any.whl (444 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.8/444.8 KB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting sentry-sdk>=2.0.0\n",
      "  Downloading sentry_sdk-2.39.0-py2.py3-none-any.whl (370 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m370.9/370.9 KB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /home/patryk/Desktop/venv/ML_venv/lib/python3.10/site-packages (from wandb) (2.32.4)\n",
      "Requirement already satisfied: packaging in /home/patryk/Desktop/venv/ML_venv/lib/python3.10/site-packages (from wandb) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /home/patryk/Desktop/venv/ML_venv/lib/python3.10/site-packages (from wandb) (6.31.1)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0\n",
      "  Downloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.2/208.2 KB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting click>=8.0.1\n",
      "  Using cached click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.8 in /home/patryk/Desktop/venv/ML_venv/lib/python3.10/site-packages (from wandb) (4.12.2)\n",
      "Requirement already satisfied: pyyaml in /home/patryk/Desktop/venv/ML_venv/lib/python3.10/site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: platformdirs in /home/patryk/Desktop/venv/ML_venv/lib/python3.10/site-packages (from wandb) (4.3.8)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting annotated-types>=0.6.0\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting typing-inspection>=0.4.0\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Collecting pydantic-core==2.33.2\n",
      "  Using cached pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/patryk/Desktop/venv/ML_venv/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2025.8.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/patryk/Desktop/venv/ML_venv/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/patryk/Desktop/venv/ML_venv/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/patryk/Desktop/venv/ML_venv/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: typing-inspection, smmap, sentry-sdk, pydantic-core, click, annotated-types, pydantic, gitdb, gitpython, wandb\n",
      "Successfully installed annotated-types-0.7.0 click-8.3.0 gitdb-4.0.12 gitpython-3.1.45 pydantic-2.11.10 pydantic-core-2.33.2 sentry-sdk-2.39.0 smmap-5.0.2 typing-inspection-0.4.2 wandb-0.22.1\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/patryk/Desktop/venv/ML_venv/bin/wandb\", line 8, in <module>\n",
      "    sys.exit(cli())\n",
      "  File \"/home/patryk/Desktop/venv/ML_venv/lib/python3.10/site-packages/click/core.py\", line 1462, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"/home/patryk/Desktop/venv/ML_venv/lib/python3.10/site-packages/click/core.py\", line 1383, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"/home/patryk/Desktop/venv/ML_venv/lib/python3.10/site-packages/click/core.py\", line 1850, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"/home/patryk/Desktop/venv/ML_venv/lib/python3.10/site-packages/click/core.py\", line 1246, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"/home/patryk/Desktop/venv/ML_venv/lib/python3.10/site-packages/click/core.py\", line 814, in invoke\n",
      "    return callback(*args, **kwargs)\n",
      "  File \"/home/patryk/Desktop/venv/ML_venv/lib/python3.10/site-packages/wandb/cli/cli.py\", line 137, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/patryk/Desktop/venv/ML_venv/lib/python3.10/site-packages/wandb/cli/cli.py\", line 277, in login\n",
      "    wandb.login(\n",
      "  File \"/home/patryk/Desktop/venv/ML_venv/lib/python3.10/site-packages/wandb/sdk/wandb_login.py\", line 80, in login\n",
      "    logged_in, _ = _login(\n",
      "  File \"/home/patryk/Desktop/venv/ML_venv/lib/python3.10/site-packages/wandb/sdk/wandb_login.py\", line 327, in _login\n",
      "    wlogin.try_save_api_key(key)\n",
      "  File \"/home/patryk/Desktop/venv/ML_venv/lib/python3.10/site-packages/wandb/sdk/wandb_login.py\", line 182, in try_save_api_key\n",
      "    apikey.write_key(self._settings, key)\n",
      "  File \"/home/patryk/Desktop/venv/ML_venv/lib/python3.10/site-packages/wandb/sdk/lib/apikey.py\", line 313, in write_key\n",
      "    raise ValueError(f\"API key must be 40 characters long, yours was {len(key)}\")\n",
      "ValueError: API key must be 40 characters long, yours was 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/patryk/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpatryklorenc\u001b[0m (\u001b[33mdeep-neural-network-course\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb\n",
    "!wandb login YOUR_API_KEY\n",
    "#wandb login YOUR_API_KEY\n",
    "\n",
    "import os\n",
    "import wandb\n",
    "\n",
    "wandb.login()\n",
    "os.environ['WANDB_API_KEY'] = '3b211912c8dd66233b84574a120f67cd273841a9'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcebc91",
   "metadata": {},
   "source": [
    "# First steps\n",
    "\n",
    "Let's start by importing the necessary libraries and checking if a GPU is available for computations. If a GPU is not available, the code will automatically fall back to using the CPU. If you are using Google Colab, you can enable GPU support by navigating to `Runtime` -> `Change runtime type` and selecting `GPU` from the `Hardware accelerator` dropdown menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a78cd326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if a GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7f294d",
   "metadata": {},
   "source": [
    "Now we can proceed to implement our first neural network layer using PyTorch. We will create a simple feedforward neural network with one hidden layer and demonstrate how to perform a forward pass with some sample input data.\n",
    "\n",
    "Documentation:\n",
    "- https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
    "- https://docs.pytorch.org/docs/stable/generated/torch.randn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "395bbfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer parameters:\n",
      "weight: torch.Size([5, 10])\n",
      "bias: torch.Size([5])\n",
      "------------------------------\n",
      "Input tensor:\n",
      "Size: torch.Size([1, 10])\n",
      "------------------------------\n",
      "Output tensor:\n",
      "Size: torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Initialize a simple feedforward neural network layer\n",
    "# Here, we create a linear layer with 10 input features and 5 output features\n",
    "# The layer is moved to the appropriate device (GPU or CPU)\n",
    "\n",
    "layer = nn.Linear(in_features=10, out_features=5, bias=True).to(device) \n",
    "\n",
    "# We can visualize the layer's variables (learnable parameters):\n",
    "print(\"Layer parameters:\")\n",
    "for name, param in layer.named_parameters():\n",
    "    print(f\"{name}: {param.size()}\")\n",
    "\n",
    "# We generate a random input tensor with 10 features and 1 batch size (number of samples)\n",
    "# We also move this tensor to the appropriate device (same as the layer)\n",
    "\n",
    "input_tensor = torch.randn(1, 10).to(device)\n",
    "print(\"-\" * 30)\n",
    "print(\"Input tensor:\")\n",
    "print(f\"Size: {input_tensor.size()}\")\n",
    "\n",
    "# Perform a forward pass through the layer\n",
    "output_tensor = layer(input_tensor)\n",
    "print(\"-\" * 30)\n",
    "print(\"Output tensor:\")\n",
    "print(f\"Size: {output_tensor.size()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11c2adcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor values:\n",
      "tensor([[ 0.1277, -0.3637, -0.5440, -0.2511,  0.1131,  0.0723,  1.1559, -0.4119,\n",
      "          1.1191,  0.5626]], device='cuda:0')\n",
      "Output tensor values:\n",
      "tensor([[ 0.4354,  0.5688, -0.3151, -0.2209,  0.5346]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Layer weights:\n",
      "Parameter containing:\n",
      "tensor([[ 0.2127, -0.0445, -0.2863, -0.0896,  0.0969,  0.1447,  0.2186,  0.0433,\n",
      "         -0.1276, -0.2865],\n",
      "        [-0.2342,  0.2312, -0.1139,  0.1147,  0.0807,  0.1913,  0.2054,  0.2887,\n",
      "          0.2937,  0.2173],\n",
      "        [-0.0182,  0.2091, -0.1609,  0.0994,  0.2003, -0.0951,  0.0570, -0.1158,\n",
      "         -0.1965, -0.2857],\n",
      "        [-0.0350, -0.2378, -0.0808,  0.2987,  0.2106, -0.2341, -0.0486,  0.2399,\n",
      "         -0.2357, -0.2871],\n",
      "        [ 0.1838, -0.1693,  0.1703,  0.1303, -0.0014,  0.1039,  0.0419, -0.2219,\n",
      "          0.0018,  0.3014]], device='cuda:0', requires_grad=True)\n",
      "Layer biases:\n",
      "Parameter containing:\n",
      "tensor([ 0.2616,  0.0573, -0.0480,  0.3016,  0.2562], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# We can visualize the input and output tensors:\n",
    "print(\"Input tensor values:\")\n",
    "print(input_tensor)\n",
    "print(\"Output tensor values:\")\n",
    "print(output_tensor)\n",
    "\n",
    "# Also print the layer's weights and biases\n",
    "print(\"Layer weights:\")\n",
    "print(layer.weight)\n",
    "print(\"Layer biases:\")\n",
    "print(layer.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e738c3",
   "metadata": {},
   "source": [
    "Below is a simple example of how to use the W&B library to log metrics during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e25f1472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/patryk/Desktop/AiR_ISS/sem2/wandb/run-20251006_104046-g3ivch18</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/deep-neural-network-course/lab1-introduction/runs/g3ivch18' target=\"_blank\">Patryk Lorenc</a></strong> to <a href='https://wandb.ai/deep-neural-network-course/lab1-introduction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/deep-neural-network-course/lab1-introduction' target=\"_blank\">https://wandb.ai/deep-neural-network-course/lab1-introduction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/deep-neural-network-course/lab1-introduction/runs/g3ivch18' target=\"_blank\">https://wandb.ai/deep-neural-network-course/lab1-introduction/runs/g3ivch18</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>█▆▅▅▁</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>loss</td><td>▂▇▁▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.12413</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>loss</td><td>0.78894</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Patryk Lorenc</strong> at: <a href='https://wandb.ai/deep-neural-network-course/lab1-introduction/runs/g3ivch18' target=\"_blank\">https://wandb.ai/deep-neural-network-course/lab1-introduction/runs/g3ivch18</a><br> View project at: <a href='https://wandb.ai/deep-neural-network-course/lab1-introduction' target=\"_blank\">https://wandb.ai/deep-neural-network-course/lab1-introduction</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251006_104046-g3ivch18/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# Initialize a W&B run\n",
    "wandb.init(\n",
    "        project=\"lab1-introduction\",            # do not change this line ! \n",
    "                                                # (this is the name of the project for each lab)\n",
    "\n",
    "        entity=\"deep-neural-network-course\",    # do not change this line ! \n",
    "                                                # (this is the name of the team for the course)\n",
    "\n",
    "        group=\"test_run\",                       # do not change this line ! \n",
    "                                                # (this is the name of the group for each lab, e.g. task1, task2, etc.)\n",
    "\n",
    "        name=\"Patryk Lorenc\",                  # change to your name \n",
    "                                                # (e.g. Johny Bravo - your full name)\n",
    "\n",
    "        settings=wandb.Settings(save_code=False)# do not change this line ! \n",
    "                                                # (this is to avoid saving all the code files in W&B, which would be too large)\n",
    ")\n",
    "\n",
    "# Log some example metrics to W&B\n",
    "for epoch in range(5):\n",
    "    # Simulate some metrics\n",
    "    loss = torch.randn(1).item()  # Random loss value\n",
    "    accuracy = torch.rand(1).item()  # Random accuracy value\n",
    "\n",
    "    # Log metrics to W&B\n",
    "    wandb.log({\"epoch\": epoch, \"loss\": loss, \"accuracy\": accuracy})\n",
    "\n",
    "# Finish the W&B run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea94048",
   "metadata": {},
   "source": [
    "And you should see the results in your W&B dashboard.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/vision-agh/DNN-Course-media/refs/heads/main/lab1_introduction/figures/test.png\" alt=\"W&B Dashboard Example\" width=\"1000\"/>\n",
    "\n",
    "For now, this is enough to get you started. In the next classes, we will delve deeper into the concepts and techniques of deep learning. If you have any questions or need assistance, feel free to ask!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9cd45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "3b211912c8dd66233b84574a120f67cd273841a9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f2cfff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
